import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  ScrollView,
  Alert,
  PermissionsAndroid,
  Platform,
  LogBox,
} from 'react-native';
import AudioRecord from 'react-native-audio-record';
import Tts from 'react-native-tts';
import RNFS from 'react-native-fs';

// íŠ¹ì • ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
LogBox.ignoreLogs([
  'new NativeEventEmitter',
  'EventEmitter.removeListener',
]);

interface Message {
  id: number;
  type: 'user' | 'ai';
  content: string;
  timestamp: string;
}

const SpeakScreen = ({ navigation }: { navigation: any }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const websocketRef = useRef<WebSocket | null>(null);
  const scrollViewRef = useRef<ScrollView>(null);
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  // [ìˆ˜ì • 4] ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™” ìˆœì„œë¥¼ ê°•ì œí•˜ëŠ” ë¡œì§
  useEffect(() => {
    initializeApp();

    // ì»´í¬ë„ŒíŠ¸ê°€ ì‚¬ë¼ì§ˆ ë•Œ ì‹¤í–‰ë˜ëŠ” ìµœì¢… ì •ë¦¬(cleanup) ë¡œì§
    return () => {
      cleanupAudio();
      if (websocketRef.current) {
        // [ìˆ˜ì • 1] ì¢€ë¹„ ì´ë²¤íŠ¸ ë°©ì§€ë¥¼ ìœ„í•œ ì›¹ì†Œì¼“ ë¦¬ì†ŒìŠ¤ ì™„ì „ í•´ì œ
        websocketRef.current.onopen = null;
        websocketRef.current.onmessage = null;
        websocketRef.current.onclose = null;
        websocketRef.current.onerror = null;
        websocketRef.current.close();
      }
    };
  }, []);

  // [ìˆ˜ì • 4] ì•ˆì •ì ì¸ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ ëª¨ë“  ê³¼ì •ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
  const initializeApp = async () => {
    try {
      await requestPermissions();
      await setupTTS();
      // connectWebSocketì€ ëª¨ë“  ì„¤ì •ì´ ëë‚œ í›„ ë§ˆì§€ë§‰ì— í˜¸ì¶œ
      connectWebSocket();
    } catch (error) {
      console.error("âŒ ì•± ì´ˆê¸°í™” ì‹¤íŒ¨:", error);
      Alert.alert("ì´ˆê¸°í™” ì˜¤ë¥˜", "ì•±ì„ ì‹œì‘í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
    }
  };

  const setupTTS = async () => {
    try {
      // ë¦¬ìŠ¤ë„ˆ ì¤‘ë³µ ë“±ë¡ ë°©ì§€ë¥¼ ìœ„í•´ í•­ìƒ ë¨¼ì € ì œê±°
      Tts.removeAllListeners('tts-start');
      Tts.removeAllListeners('tts-finish');
      Tts.removeAllListeners('tts-cancel');

      Tts.addEventListener('tts-start', () => setIsSpeaking(true));
      Tts.addEventListener('tts-finish', () => {
        setIsSpeaking(false);
        setTimeout(() => {
          if (!isRecording && !isProcessing) {
            startRecording();
          }
        }, 1000);
      });
      Tts.addEventListener('tts-cancel', () => setIsSpeaking(false));

      await Tts.setDefaultLanguage('ko-KR');
      await Tts.setDefaultRate(0.5);
    } catch (error) {
      console.error('TTS ì„¤ì • ì˜¤ë¥˜:', error);
      // TTS ì„¤ì • ì‹¤íŒ¨ëŠ” ì‹¬ê°í•œ ë¬¸ì œì´ë¯€ë¡œ ì—ëŸ¬ë¥¼ ë˜ì ¸ initializeAppì—ì„œ ì²˜ë¦¬
      throw new Error('TTS setup failed');
    }
  };

  const requestPermissions = async () => {
    if (Platform.OS === 'android') {
      try {
        const granted = await PermissionsAndroid.request(
          PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
          {
            title: 'ìŒì„± ì¸ì‹ ê¶Œí•œ',
            message: 'ìŒì„± ëŒ€í™”ë¥¼ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
            buttonPositive: 'í™•ì¸',
            buttonNegative: 'ì·¨ì†Œ',
          },
        );
        if (granted !== PermissionsAndroid.RESULTS.GRANTED) {
          Alert.alert('ê¶Œí•œ í•„ìš”', 'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
          throw new Error('Permission denied');
        }
      } catch (err) {
        console.error('ê¶Œí•œ ìš”ì²­ ì˜¤ë¥˜:', err);
        throw err; // ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë˜ì ¸ì„œ ì´ˆê¸°í™” ì¤‘ë‹¨
      }
    }
  };

  const connectWebSocket = () => {
    try {
      // [ìˆ˜ì • 1] ì¬ì—°ê²° ì‹œ ì´ì „ ì›¹ì†Œì¼“ ê°ì²´ë¥¼ ì™„ì „íˆ ì •ë¦¬í•˜ì—¬ ì¶©ëŒ ë°©ì§€
      if (websocketRef.current) {
        websocketRef.current.onopen = null;
        websocketRef.current.onmessage = null;
        websocketRef.current.onclose = null;
        websocketRef.current.onerror = null;
        websocketRef.current.close();
      }

      console.log('ğŸ”— WebSocket ì—°ê²° ì‹œë„: ws://localhost:8000/ws/chat');
      websocketRef.current = new WebSocket('ws://localhost:8000/ws/chat');

      websocketRef.current.onopen = () => {
        setIsConnected(true);
        console.log('âœ… WebSocket ì—°ê²° ì„±ê³µ');
      };

      websocketRef.current.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          console.log('ğŸ“¨ ë°›ì€ ë©”ì‹œì§€:', data);

          if (data.type === 'ai_message') {
            handleAIMessage(data.content);
            setIsProcessing(false);
          } else if (data.type === 'user_message') {
            handleUserMessage(data.content);
          } else if (data.type === 'error') {
            Alert.alert('ì²˜ë¦¬ ì˜¤ë¥˜', data.content);
            setIsProcessing(false);
          }
        } catch (error) {
          console.error('âŒ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
          setIsProcessing(false);
        }
      };

      websocketRef.current.onclose = (event) => {
        setIsConnected(false);
        console.log('âŒ WebSocket ì—°ê²° ì¢…ë£Œ. Code:', event.code, 'Reason:', event.reason);
        setTimeout(() => {
          // ì•±ì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œë§Œ ì¬ì—°ê²° ì‹œë„
          if (navigation.isFocused()) {
            console.log('ğŸ”„ WebSocket ì¬ì—°ê²° ì‹œë„');
            connectWebSocket();
          }
        }, 3000);
      };

      websocketRef.current.onerror = (error) => {
        console.error('âŒ WebSocket ì˜¤ë¥˜:', error.message);
        setIsConnected(false);
      };
    } catch (error) {
      console.error('âŒ WebSocket ì—°ê²° ì‹¤íŒ¨:', error);
      Alert.alert('ì—°ê²° ì‹¤íŒ¨', 'ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  const startRecording = async () => {
    if (isSpeaking || isProcessing) {
      console.log('ğŸ”Š AIê°€ ë§í•˜ëŠ” ì¤‘ì´ê±°ë‚˜ ì²˜ë¦¬ ì¤‘ì´ë¯€ë¡œ ë…¹ìŒ ì‹œì‘í•˜ì§€ ì•ŠìŒ');
      return;
    }

    try {
      // [ìˆ˜ì • 2] ë…¹ìŒ ì‹œì‘ ì§ì „ì— í•­ìƒ ì˜¤ë””ì˜¤ ëª¨ë“ˆì„ ì¬ì´ˆê¸°í™”í•˜ì—¬ ì¶©ëŒ ë°©ì§€
      const options = {
        sampleRate: 16000,
        channels: 1,
        bitsPerSample: 16,
        audioSource: 6, // VOICE_RECOGNITION
        wavFile: 'voice_recording.wav'
      };
      AudioRecord.init(options);

      setIsRecording(true);
      console.log('ğŸ¤ ìŒì„± ë…¹ìŒ ì‹œì‘');
      AudioRecord.start();

      if (recordingTimeoutRef.current) clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = setTimeout(() => {
        if (isRecording) {
          console.log('â° 10ì´ˆ ë¬´ìŒ - ëŒ€í™” ì¢…ë£Œ');
          stopRecording();
          Alert.alert('ëŒ€í™” ì¢…ë£Œ', 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.', [
            { text: 'í™•ì¸', onPress: () => navigation.goBack() }
          ]);
        }
      }, 10000);
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error);
      setIsRecording(false);
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ìŒì„± ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  const stopRecording = async () => {
    if (!isRecording) return;

    try {
      setIsRecording(false);
      setIsProcessing(true);

      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
        recordingTimeoutRef.current = null;
      }

      console.log('ğŸ›‘ ìŒì„± ë…¹ìŒ ì¤‘ì§€');
      const audioFile = await AudioRecord.stop();
      console.log('ğŸ“ ë…¹ìŒ íŒŒì¼:', audioFile);

      const audioBase64 = await RNFS.readFile(audioFile, 'base64');

      if (websocketRef.current && isConnected) {
        websocketRef.current.send(JSON.stringify({
          type: 'audio_data',
          audio: audioBase64
        }));
        console.log('ğŸ“¤ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ë¨');
      }
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:', error);
      setIsRecording(false);
      setIsProcessing(false);
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleUserMessage = (message: string) => {
    setMessages(prev => [...prev, {
      id: Date.now(),
      type: 'user',
      content: message,
      timestamp: new Date().toLocaleTimeString()
    }]);
  };

  const handleAIMessage = (message: string) => {
    setMessages(prev => [...prev, {
      id: Date.now(),
      type: 'ai',
      content: message,
      timestamp: new Date().toLocaleTimeString()
    }]);
    speakMessage(message);
  };

  const speakMessage = async (message: string) => {
    try {
      await Tts.speak(message);
    } catch (error) {
      console.error('âŒ TTS ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
    }
  };

  const cleanupAudio = async () => {
    try {
      if (isRecording) {
        await AudioRecord.stop();
      }
      Tts.stop();
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
    } catch (error) {
      console.error('âŒ Audio cleanup ì˜¤ë¥˜:', error);
    }
  };

  const handleEndConversation = () => {
    Alert.alert(
      'ëŒ€í™” ì¢…ë£Œ',
      'ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?',
      [
        { text: 'ì·¨ì†Œ', style: 'cancel' },
        {
          text: 'ì¢…ë£Œ',
          style: 'destructive',
          onPress: () => navigation.goBack() // cleanupì€ useEffectì˜ returnì—ì„œ ì²˜ë¦¬ë¨
        }
      ]
    );
  };

  const getStatusText = () => {
    if (isSpeaking) return 'ğŸ”Š AI ë§í•˜ëŠ” ì¤‘...';
    if (isProcessing) return 'âš™ï¸ ìŒì„± ì²˜ë¦¬ ì¤‘...';
    if (isRecording) return 'ğŸ¤ ë…¹ìŒ ì¤‘...';
    return 'ëŒ€ê¸° ì¤‘';
  };

  const getStatusColor = () => {
    if (isSpeaking) return '#FF9800';
    if (isProcessing) return '#2196F3';
    if (isRecording) return '#4CAF50';
    return '#666';
  };

  // (ìŠ¤íƒ€ì¼ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤)
  return (
    <View style={styles.container}>
      <View style={styles.header}>
        <Text style={styles.title}>AI ìŒì„± ëŒ€í™”</Text>
        <View style={styles.statusContainer}>
          <View style={[styles.statusIndicator, { backgroundColor: isConnected ? '#4CAF50' : '#F44336' }]} />
          <Text style={[styles.statusText, { color: getStatusColor() }]}>
            {getStatusText()}
          </Text>
        </View>
      </View>
      <ScrollView
        ref={scrollViewRef}
        style={styles.messagesContainer}
        onContentSizeChange={() => scrollViewRef.current?.scrollToEnd({ animated: true })}
      >
        {messages.map((message) => (
          <View key={message.id} style={[
            styles.messageContainer,
            message.type === 'user' ? styles.userMessage : styles.aiMessage
          ]}>
            <Text style={[
              styles.messageText,
              message.type === 'user' ? styles.userMessageText : styles.aiMessageText
            ]}>
              {message.content}
            </Text>
            <Text style={styles.timestamp}>{message.timestamp}</Text>
          </View>
        ))}
      </ScrollView>
      <View style={styles.controlsContainer}>
        <TouchableOpacity
          style={[
            styles.recordButton,
            isRecording && styles.recordingButton,
            (!isConnected || isSpeaking || isProcessing) && styles.disabledButton
          ]}
          onPress={isRecording ? stopRecording : startRecording}
          disabled={!isConnected || isSpeaking || isProcessing}
        >
          <Text style={styles.recordButtonText}>
            {isRecording ? 'ğŸ¤ ë…¹ìŒ ì¤‘... (íƒ­í•˜ë©´ ì¤‘ì§€)' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
          </Text>
        </TouchableOpacity>
        <TouchableOpacity
          style={styles.endButton}
          onPress={handleEndConversation}
        >
          <Text style={styles.endButtonText}>ëŒ€í™” ì¢…ë£Œ</Text>
        </TouchableOpacity>
      </View>
    </View>
  );
};

// ìŠ¤íƒ€ì¼ ì½”ë“œëŠ” ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.
const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f5f5f5',
    paddingTop: 50,
  },
  header: {
    padding: 20,
    backgroundColor: '#fff',
    borderBottomWidth: 1,
    borderBottomColor: '#eee',
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#333',
    marginBottom: 10,
  },
  statusContainer: {
    flexDirection: 'row',
    alignItems: 'center',
  },
  statusIndicator: {
    width: 12,
    height: 12,
    borderRadius: 6,
    marginRight: 10,
  },
  statusText: {
    fontSize: 16,
    fontWeight: '600',
  },
  messagesContainer: {
    flex: 1,
    padding: 20,
  },
  messageContainer: {
    marginVertical: 8,
    padding: 15,
    borderRadius: 15,
    maxWidth: '85%',
  },
  userMessage: {
    alignSelf: 'flex-end',
    backgroundColor: '#007AFF',
  },
  aiMessage: {
    alignSelf: 'flex-start',
    backgroundColor: '#E5E5EA',
  },
  messageText: {
    fontSize: 16,
    lineHeight: 22,
  },
  userMessageText: {
    color: '#fff',
  },
  aiMessageText: {
    color: '#333',
  },
  timestamp: {
    fontSize: 12,
    color: '#999',
    marginTop: 5,
    alignSelf: 'flex-end',
  },
  controlsContainer: {
    padding: 20,
    backgroundColor: '#fff',
    borderTopWidth: 1,
    borderTopColor: '#eee',
  },
  recordButton: {
    backgroundColor: '#4CAF50',
    paddingVertical: 15,
    paddingHorizontal: 30,
    borderRadius: 25,
    alignItems: 'center',
    marginBottom: 10,
  },
  recordingButton: {
    backgroundColor: '#FF9800',
  },
  disabledButton: {
    backgroundColor: '#ccc',
  },
  recordButtonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: '600',
  },
  endButton: {
    backgroundColor: '#FF3B30',
    paddingVertical: 15,
    paddingHorizontal: 30,
    borderRadius: 25,
    alignItems: 'center',
  },
  endButtonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: '600',
  },
});

export default SpeakScreen;