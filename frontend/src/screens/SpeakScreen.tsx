import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  ScrollView,
  Alert,
  PermissionsAndroid,
  Platform,
  LogBox,
} from 'react-native';
import AsyncStorage from '@react-native-async-storage/async-storage';
import AudioRecord from 'react-native-audio-record';
import Tts from 'react-native-tts';
import RNFS from 'react-native-fs';

LogBox.ignoreLogs([
  'new NativeEventEmitter',
  'EventEmitter.removeListener',
]);

interface Message {
  id: number;
  type: 'user' | 'ai';
  content: string;
  timestamp: string;
}

const SpeakScreen = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [userId, setUserId] = useState<string | null>(null);
  const websocketRef = useRef<WebSocket | null>(null);
  const scrollViewRef = useRef<ScrollView>(null);
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  // âœ… 1. ì¬ì—°ê²° ì‹œë„ íšŸìˆ˜ë¥¼ ì„¸ê¸° ìœ„í•œ Ref ì¶”ê°€
  const retryCountRef = useRef(0);
  // âœ… 2. ì‚¬ìš©ìê°€ ì§ì ‘ ì¢…ë£Œí–ˆëŠ”ì§€ ìƒíƒœë¥¼ ì¶”ì 
  const userClosedConnection = useRef(false);

  useEffect(() => {
    const setupUserAndInitialize = async () => {
      try {
        let id = await AsyncStorage.getItem('user_id');
        if (!id) {
          id = `user_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
          await AsyncStorage.setItem('user_id', id);
        }
        setUserId(id);
      } catch (e) {
        Alert.alert('ì˜¤ë¥˜', 'ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    };
    setupUserAndInitialize();

    return () => {
      // ì»´í¬ë„ŒíŠ¸ê°€ ì‚¬ë¼ì§ˆ ë•Œ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      cleanupAudio();
      if (websocketRef.current) {
        userClosedConnection.current = true; // ì»´í¬ë„ŒíŠ¸ unmount ì‹œ ì‚¬ìš©ìê°€ ì¢…ë£Œí•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
        websocketRef.current.close();
      }
    };
  }, []);

  useEffect(() => {
    if (userId) {
      initializeApp();
    }
  }, [userId]);

  const initializeApp = async () => {
    try {
      await requestPermissions();
      await setupTTS();
      userClosedConnection.current = false; // ì•± ì´ˆê¸°í™” ì‹œ ì¬ì—°ê²° í—ˆìš©
      connectWebSocket();
    } catch (error) {
      Alert.alert("ì´ˆê¸°í™” ì˜¤ë¥˜", "ì•±ì„ ì‹œì‘í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
    }
  };

  const setupTTS = async () => {
    Tts.removeAllListeners('tts-start');
    Tts.removeAllListeners('tts-finish');
    Tts.removeAllListeners('tts-cancel');
    Tts.addEventListener('tts-start', () => setIsSpeaking(true));
    Tts.addEventListener('tts-finish', () => {
      setIsSpeaking(false);
      setTimeout(() => {
        if (!isRecording && !isProcessing) {
          startRecording();
        }
      }, 1000);
    });
    Tts.addEventListener('tts-cancel', () => setIsSpeaking(false));
    await Tts.setDefaultLanguage('ko-KR');
    await Tts.setDefaultRate(0.5);
  };

  const requestPermissions = async () => {
    // ... (ì´ì „ê³¼ ë™ì¼)
    if (Platform.OS === 'android') {
        try {
          const granted = await PermissionsAndroid.request(
            PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
            {
              title: 'ìŒì„± ì¸ì‹ ê¶Œí•œ',
              message: 'ìŒì„± ëŒ€í™”ë¥¼ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
              buttonPositive: 'í™•ì¸',
              buttonNegative: 'ì·¨ì†Œ',
            },
          );
          if (granted !== PermissionsAndroid.RESULTS.GRANTED) {
            Alert.alert('ê¶Œí•œ í•„ìš”', 'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
            throw new Error('Permission denied');
          }
        } catch (err) {
          console.error('ê¶Œí•œ ìš”ì²­ ì˜¤ë¥˜:', err);
          throw err;
        }
      }
  };

  const connectWebSocket = () => {
    if (!userId) return;

    // â—ï¸â—ï¸ <ì„œë²„ IP ì£¼ì†Œ> ë¶€ë¶„ì€ ì‹¤ì œ PC IPë¡œ ë³€ê²½í•´ì£¼ì„¸ìš” â—ï¸â—ï¸
    const wsUrl = `ws://192.168.101.67:8888/ws/chat?user_id=${userId}`; // í¬íŠ¸ 8888 ì‚¬ìš©
    console.log(`ğŸ”— WebSocket ì—°ê²° ì‹œë„: ${wsUrl}`);
    websocketRef.current = new WebSocket(wsUrl);

    websocketRef.current.onopen = () => {
      setIsConnected(true);
      console.log('âœ… WebSocket ì—°ê²° ì„±ê³µ');
      // âœ… 3. ì—°ê²° ì„±ê³µ ì‹œ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê¸°í™”
      retryCountRef.current = 0;
    };

    websocketRef.current.onmessage = (event) => {
      // ... (ì´ì „ê³¼ ë™ì¼)
        try {
          const data = JSON.parse(event.data);
          console.log('ğŸ“¨ ë°›ì€ ë©”ì‹œì§€:', data);

          if (data.type === 'ai_message') {
            handleAIMessage(data.content);
            setIsProcessing(false);
          } else if (data.type === 'user_message') {
            handleUserMessage(data.content);
          } else if (data.type === 'error') {
            Alert.alert('ì²˜ë¦¬ ì˜¤ë¥˜', data.content);
            setIsProcessing(false);
          }
        } catch (error) {
          console.error('âŒ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
          setIsProcessing(false);
        }
    };

    // âœ… 4. ì•ˆì •ì ì¸ ì¬ì—°ê²° ë¡œì§ìœ¼ë¡œ ìˆ˜ì •
    websocketRef.current.onclose = (event) => {
      setIsConnected(false);
      console.log('âŒ WebSocket ì—°ê²° ì¢…ë£Œ. Code:', event.code, 'Reason:', event.reason);
      
      // ì‚¬ìš©ìê°€ ì§ì ‘ ì¢…ë£Œí–ˆê±°ë‚˜, ì»´í¬ë„ŒíŠ¸ê°€ ì‚¬ë¼ì§„ ê²½ìš°ì—ëŠ” ì¬ì—°ê²° ì•ˆ í•¨
      if (userClosedConnection.current) {
        console.log('ì‚¬ìš©ìê°€ ì—°ê²°ì„ ì¢…ë£Œí•˜ì—¬ ì¬ì—°ê²°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
        return;
      }
      
      if (retryCountRef.current < 5) {
        retryCountRef.current += 1;
        console.log(`ğŸ”„ WebSocket ì¬ì—°ê²° ì‹œë„ (${retryCountRef.current}/5)`);
        setTimeout(connectWebSocket, 3000);
      } else {
        console.log('ìµœëŒ€ ì¬ì—°ê²° íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
        Alert.alert('ì—°ê²° ì‹¤íŒ¨', 'ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ì•±ì„ ë‹¤ì‹œ ì‹œì‘í•´ ì£¼ì„¸ìš”.');
      }
    };

    websocketRef.current.onerror = (error) => {
      console.error('âŒ WebSocket ì˜¤ë¥˜:', error.message);
      setIsConnected(false);
    };
  };

  const startRecording = async () => {
    // ... (ì´ì „ê³¼ ë™ì¼)
    if (isSpeaking || isProcessing) return;
    try {
      const options = { sampleRate: 16000, channels: 1, bitsPerSample: 16, audioSource: 6, wavFile: 'voice_recording.wav' };
      AudioRecord.init(options);
      AudioRecord.start();
      setIsRecording(true);
      if (recordingTimeoutRef.current) clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = setTimeout(() => {
        if (isRecording) {
          stopRecording();
          Alert.alert('ëŒ€í™” ì¢…ë£Œ', 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.');
        }
      }, 10000);
    } catch (error) {
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ìŒì„± ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  const stopRecording = async () => {
    // ... (ì´ì „ê³¼ ë™ì¼)
    if (!isRecording) return;
    try {
      setIsRecording(false);
      setIsProcessing(true);
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
        recordingTimeoutRef.current = null;
      }
      const audioFile = await AudioRecord.stop();
      const audioBase64 = await RNFS.readFile(audioFile, 'base64');
      if (websocketRef.current && isConnected) {
        websocketRef.current.send(JSON.stringify({ type: 'audio_data', audio: audioBase64 }));
      }
    } catch (error) {
      setIsProcessing(false);
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleUserMessage = (message: string) => {
    // ... (ì´ì „ê³¼ ë™ì¼)
     setMessages(prev => [...prev, { id: Date.now(), type: 'user', content: message, timestamp: new Date().toLocaleTimeString() }]);
  };

  const handleAIMessage = (message: string) => {
    // ... (ì´ì „ê³¼ ë™ì¼)
    setMessages(prev => [...prev, { id: Date.now(), type: 'ai', content: message, timestamp: new Date().toLocaleTimeString() }]);
    speakMessage(message);
  };

  const speakMessage = async (message: string) => {
    // ... (ì´ì „ê³¼ ë™ì¼)
     try {
      await Tts.speak(message);
    } catch (error) {
      setIsSpeaking(false);
    }
  };

  const cleanupAudio = () => {
    // ... (ì´ì „ê³¼ ë™ì¼, async ì œê±°)
    try {
      AudioRecord.stop(); // isRecording ìƒíƒœì™€ ë¬´ê´€í•˜ê²Œ ì¼ë‹¨ ì¤‘ì§€ ì‹œë„
      Tts.stop();
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
    } catch (error) {
      console.error('âŒ Audio cleanup ì˜¤ë¥˜:', error);
    }
  };

  // âœ… 5. ëŒ€í™” ì¢…ë£Œ ê¸°ëŠ¥ ìˆ˜ì •
  const handleEndConversation = () => {
    Alert.alert(
      'ëŒ€í™” ì¢…ë£Œ',
      'ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê³  ì„¸ì…˜ì„ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ?',
      [
        { text: 'ì·¨ì†Œ', style: 'cancel' },
        {
          text: 'ì¢…ë£Œ',
          style: 'destructive',
          onPress: () => {
            console.log('--- ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ ---');
            // ëª¨ë“  ì˜¤ë””ì˜¤/ë…¹ìŒ ì¤‘ì§€
            cleanupAudio(); 
            // ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ (ì¬ì—°ê²° ì•ˆ í•˜ë„ë¡ í”Œë˜ê·¸ ì„¤ì •)
            userClosedConnection.current = true;
            websocketRef.current?.close(); 
            // ìƒíƒœ ì´ˆê¸°í™”
            setIsRecording(false);
            setIsSpeaking(false);
            setIsProcessing(false);
            setMessages([]); // ë©”ì‹œì§€ ëª©ë¡ ë¹„ìš°ê¸°
          }
        }
      ]
    );
  };
  
  // getStatusText, getStatusColor, JSX, stylesëŠ” ì´ì „ê³¼ ë™ì¼
  const getStatusText = () => {
    if (isSpeaking) return 'ğŸ”Š AI ë§í•˜ëŠ” ì¤‘...';
    if (isProcessing) return 'âš™ï¸ ìŒì„± ì²˜ë¦¬ ì¤‘...';
    if (isRecording) return 'ğŸ¤ ë…¹ìŒ ì¤‘...';
    if (!isConnected) return 'ğŸ”Œ ì—°ê²° ì¤‘...';
    return 'ëŒ€ê¸° ì¤‘';
  };

  const getStatusColor = () => {
    if (isSpeaking) return '#FF9800';
    if (isProcessing) return '#2196F3';
    if (isRecording) return '#4CAF50';
    if (!isConnected) return '#F44336';
    return '#666';
  };

  return (
    <View style={styles.container}>
      <View style={styles.header}>
        <Text style={styles.title}>AI ìŒì„± ëŒ€í™”</Text>
        <View style={styles.statusContainer}>
          <View style={[styles.statusIndicator, { backgroundColor: isConnected ? '#4CAF50' : '#F44336' }]} />
          <Text style={[styles.statusText, { color: getStatusColor() }]}>
            {getStatusText()}
          </Text>
        </View>
      </View>
      <ScrollView
        ref={scrollViewRef}
        style={styles.messagesContainer}
        onContentSizeChange={() => scrollViewRef.current?.scrollToEnd({ animated: true })}
      >
        {messages.map((message) => (
          <View key={message.id} style={[
            styles.messageContainer,
            message.type === 'user' ? styles.userMessage : styles.aiMessage
          ]}>
            <Text style={[
              styles.messageText,
              message.type === 'user' ? styles.userMessageText : styles.aiMessageText
            ]}>
              {message.content}
            </Text>
            <Text style={styles.timestamp}>{message.timestamp}</Text>
          </View>
        ))}
      </ScrollView>
      <View style={styles.controlsContainer}>
        <TouchableOpacity
          style={[
            styles.recordButton,
            isRecording && styles.recordingButton,
            (!isConnected || isSpeaking || isProcessing) && styles.disabledButton
          ]}
          onPress={isRecording ? stopRecording : startRecording}
          disabled={!isConnected || isSpeaking || isProcessing}
        >
          <Text style={styles.recordButtonText}>
            {isRecording ? 'ğŸ¤ ë…¹ìŒ ì¤‘... (íƒ­í•˜ë©´ ì¤‘ì§€)' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
          </Text>
        </TouchableOpacity>
        <TouchableOpacity
          style={styles.endButton}
          onPress={handleEndConversation}
        >
          <Text style={styles.endButtonText}>ëŒ€í™” ì¢…ë£Œ</Text>
        </TouchableOpacity>
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  // ... (ì´ì „ê³¼ ë™ì¼)
  container: { flex: 1, backgroundColor: '#f5f5f5', paddingTop: 50, },
  header: { padding: 20, backgroundColor: '#fff', borderBottomWidth: 1, borderBottomColor: '#eee', },
  title: { fontSize: 24, fontWeight: 'bold', color: '#333', marginBottom: 10, },
  statusContainer: { flexDirection: 'row', alignItems: 'center', },
  statusIndicator: { width: 12, height: 12, borderRadius: 6, marginRight: 10, },
  statusText: { fontSize: 16, fontWeight: '600', },
  messagesContainer: { flex: 1, padding: 20, },
  messageContainer: { marginVertical: 8, padding: 15, borderRadius: 15, maxWidth: '85%', },
  userMessage: { alignSelf: 'flex-end', backgroundColor: '#007AFF', },
  aiMessage: { alignSelf: 'flex-start', backgroundColor: '#E5E5EA', },
  messageText: { fontSize: 16, lineHeight: 22, },
  userMessageText: { color: '#fff', },
  aiMessageText: { color: '#333', },
  timestamp: { fontSize: 12, color: '#999', marginTop: 5, alignSelf: 'flex-end', },
  controlsContainer: { padding: 20, backgroundColor: '#fff', borderTopWidth: 1, borderTopColor: '#eee', },
  recordButton: { backgroundColor: '#4CAF50', paddingVertical: 15, paddingHorizontal: 30, borderRadius: 25, alignItems: 'center', marginBottom: 10, },
  recordingButton: { backgroundColor: '#FF9800', },
  disabledButton: { backgroundColor: '#ccc', },
  recordButtonText: { color: '#fff', fontSize: 16, fontWeight: '600', },
  endButton: { backgroundColor: '#FF3B30', paddingVertical: 15, paddingHorizontal: 30, borderRadius: 25, alignItems: 'center', },
  endButtonText: { color: '#fff', fontSize: 16, fontWeight: '600', },
});

export default SpeakScreen;